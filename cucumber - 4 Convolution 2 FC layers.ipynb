{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chuyển lại default interpolation về 'bilinear' như matplotlib 1.4.0, thay vì 'nearest' như 2.0.0\n",
    "# chế độ 'nearest' tự động resample, nên ta cũng phải chỉnh lại thông số này\n",
    "# https://matplotlib.org/users/dflt_style_changes.html#interpolation \n",
    "matplotlib.rcParams['image.interpolation'] = 'bilinear'\n",
    "matplotlib.rcParams['image.resample'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neuronsX = number of neurons in layer X\n",
    "\n",
    "# convolution\n",
    "neurons1 = 32\n",
    "neurons2 = 64\n",
    "neurons3 = 128\n",
    "neurons4 = 256\n",
    "\n",
    "# FC\n",
    "fc_neurons1 = 2**9\n",
    "fc_neurons2 = 2**6\n",
    "\n",
    "# others\n",
    "LEARNING_RATE = 1e-4\n",
    "KEEP_PROBABILITY = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 3 rows per image (for R G B); flatten (32x32 = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    fo = open(filename, 'rb')\n",
    "    fdict = cPickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return fdict\n",
    "def flatten_image(image):\n",
    "    return [item for sublist in image for item in sublist]\n",
    "\n",
    "def format_data(data):\n",
    "    images = []\n",
    "    data_size = int(len(data)/3)\n",
    "    for i in range(data_size):\n",
    "        images.append(flatten_image(data[3*i:3*i+3]))\n",
    "    return images\n",
    "\n",
    "def format_label(labels):\n",
    "    prep = [np.array([0]*9) for i in range(len(labels))]\n",
    "    for i in range(len(labels)):\n",
    "        prep[i][labels[i]] += 1\n",
    "    return prep\n",
    "\n",
    "def get_batch(filename):\n",
    "    data_batch = unpickle(filename)\n",
    "    data = format_data(data_batch['data'])\n",
    "    labels = format_label(data_batch['labels'])\n",
    "    return data, labels\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 3*32*32])\n",
    "x_image = tf.reshape(x, [-1,32,32,3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([2, 2, 3, neurons1])\n",
    "b_conv1 = bias_variable([neurons1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([2, 2, neurons1, neurons2])\n",
    "b_conv2 = bias_variable([neurons2])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv3 = weight_variable([2, 2, neurons2, neurons3])\n",
    "b_conv3 = bias_variable([neurons3])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4 (Convolutional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv4 = weight_variable([2, 2, neurons3, neurons4])\n",
    "b_conv4 = bias_variable([neurons4])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n",
    "h_pool4 = max_pool_2x2(h_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([2 * 2 * neurons4, fc_neurons1])\n",
    "b_fc1 = bias_variable([neurons4])\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4, [-1, 2*2*neurons4])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([fc_neurons1, fc_neurons2])\n",
    "b_fc2 = bias_variable([fc_neurons2])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final layer (softmax, with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc3 = weight_variable([fc_neurons2, 9])\n",
    "b_fc3 = bias_variable([9])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_cycle():\n",
    "    train_order = list(range(1, 6))\n",
    "    shuffle(train_order)\n",
    "    for i in train_order:\n",
    "        batch_xs, batch_ys = get_batch('cucumber_data/p1/data_batch_{}'.format(i))\n",
    "        train_step.run(feed_dict={x: batch_xs, y_: batch_ys, keep_prob: KEEP_PROBABILITY})\n",
    "    \n",
    "def test_cycle():\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    test_x, test_y = get_batch('cucumber_data/p1/test_batch')\n",
    "    print(sess.run(accuracy, feed_dict={x: test_x,\n",
    "                                      y_: test_y,\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "0.0969697\n",
      "Round 10\n",
      "0.276768\n",
      "Round 20\n",
      "0.327273\n",
      "Round 30\n",
      "0.353535\n",
      "Round 40\n",
      "0.393939\n",
      "Round 50\n",
      "0.414141\n",
      "Round 60\n",
      "0.448485\n",
      "Round 70\n",
      "0.478788\n",
      "Round 80\n",
      "0.490909\n",
      "Round 90\n",
      "0.49697\n",
      "Round 100\n",
      "0.515152\n",
      "Round 110\n",
      "0.519192\n",
      "Round 120\n",
      "0.535354\n",
      "Round 130\n",
      "0.543434\n",
      "Round 140\n",
      "0.553535\n",
      "Round 150\n",
      "0.565657\n",
      "Round 160\n",
      "0.573737\n",
      "Round 170\n",
      "0.567677\n",
      "Round 180\n",
      "0.577778\n",
      "Round 190\n",
      "0.583838\n"
     ]
    }
   ],
   "source": [
    "for i in range(600):\n",
    "    train_cycle()\n",
    "    if i % 20 == 0:\n",
    "        print(\"Round {}\".format(i))\n",
    "        test_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 200\n",
      "0.593939\n",
      "Round 210\n",
      "0.581818\n",
      "Round 220\n",
      "0.59596\n",
      "Round 230\n",
      "0.60404\n",
      "Round 240\n",
      "0.60404\n",
      "Round 250\n",
      "0.59596\n",
      "Round 260\n",
      "0.60202\n",
      "Round 270\n",
      "0.589899\n",
      "Round 280\n",
      "0.606061\n",
      "Round 290\n",
      "0.614141\n",
      "Round 300\n",
      "0.610101\n",
      "Round 310\n",
      "0.628283\n",
      "Round 320\n",
      "0.612121\n",
      "Round 330\n",
      "0.616162\n",
      "Round 340\n",
      "0.606061\n",
      "Round 350\n",
      "0.628283\n",
      "Round 360\n",
      "0.616162\n",
      "Round 370\n",
      "0.616162\n",
      "Round 380\n",
      "0.624242\n",
      "Round 390\n",
      "0.622222\n",
      "Round 400\n",
      "0.632323\n",
      "Round 410\n",
      "0.622222\n",
      "Round 420\n",
      "0.630303\n",
      "Round 430\n",
      "0.616162\n",
      "Round 440\n",
      "0.620202\n",
      "Round 450\n",
      "0.638384\n",
      "Round 460\n",
      "0.638384\n",
      "Round 470\n",
      "0.626263\n",
      "Round 480\n",
      "0.636364\n",
      "Round 490\n",
      "0.612121\n",
      "Round 500\n",
      "0.644444\n",
      "Round 510\n",
      "0.636364\n",
      "Round 520\n",
      "0.632323\n",
      "Round 530\n",
      "0.638384\n",
      "Round 540\n",
      "0.638384\n",
      "Round 550\n",
      "0.658586\n",
      "Round 560\n",
      "0.636364\n",
      "Round 570\n",
      "0.634343\n"
     ]
    }
   ],
   "source": [
    "for i in range(400):\n",
    "    train_cycle()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Round {}\".format(200 + i))\n",
    "        test_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
