{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chuyển lại default interpolation về 'bilinear' như matplotlib 1.4.0, thay vì 'nearest' như 2.0.0\n",
    "# chế độ 'nearest' tự động resample, nên ta cũng phải chỉnh lại thông số này\n",
    "# https://matplotlib.org/users/dflt_style_changes.html#interpolation \n",
    "matplotlib.rcParams['image.interpolation'] = 'bilinear'\n",
    "matplotlib.rcParams['image.resample'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neuronX = number of neurons in layer X\n",
    "\n",
    "# convolution\n",
    "neurons1 = 32\n",
    "neurons2 = 64\n",
    "neurons3 = 128\n",
    "\n",
    "# FC\n",
    "neurons4 = 2**8\n",
    "neurons5 = 2**7\n",
    "\n",
    "# others\n",
    "LEARNING_RATE = 1e-4\n",
    "KEEP_PROBABILITY = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 3 rows per image (for R G B); flatten (32x32 = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    fo = open(filename, 'rb')\n",
    "    fdict = cPickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return fdict\n",
    "def flatten_image(image):\n",
    "    return [item for sublist in image for item in sublist]\n",
    "\n",
    "def format_data(data):\n",
    "    images = []\n",
    "    data_size = int(len(data)/3)\n",
    "    for i in range(data_size):\n",
    "        images.append(flatten_image(data[3*i:3*i+3]))\n",
    "    return images\n",
    "\n",
    "def format_label(labels):\n",
    "    prep = [np.array([0]*9) for i in range(len(labels))]\n",
    "    for i in range(len(labels)):\n",
    "        prep[i][labels[i]] += 1\n",
    "    return prep\n",
    "\n",
    "def get_batch(filename):\n",
    "    data_batch = unpickle(filename)\n",
    "    data = format_data(data_batch['data'])\n",
    "    labels = format_label(data_batch['labels'])\n",
    "    return data, labels\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 3*32*32])\n",
    "x_image = tf.reshape(x, [-1,32,32,3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([2, 2, 3, neurons1])\n",
    "b_conv1 = bias_variable([neurons1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([2, 2, neurons1, neurons2])\n",
    "b_conv2 = bias_variable([neurons2])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3 (Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv3 = weight_variable([2, 2, neurons2, neurons3])\n",
    "b_conv3 = bias_variable([neurons3])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4 (Densely connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([4 * 4 * neurons3, neurons4])\n",
    "b_fc1 = bias_variable([neurons4])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 4*4*neurons3])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([neurons4, neurons5])\n",
    "b_fc2 = bias_variable([neurons5])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 5 (softmax, with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc3 = weight_variable([neurons5, 9])\n",
    "b_fc3 = bias_variable([9])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_cycle():\n",
    "    train_order = list(range(1, 6))\n",
    "    shuffle(train_order)\n",
    "    for i in train_order:\n",
    "        batch_xs, batch_ys = get_batch('cucumber_data/p1/data_batch_{}'.format(i))\n",
    "        train_step.run(feed_dict={x: batch_xs, y_: batch_ys, keep_prob: KEEP_PROBABILITY})\n",
    "    \n",
    "def test_cycle():\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    test_x, test_y = get_batch('cucumber_data/p1/test_batch')\n",
    "    print(sess.run(accuracy, feed_dict={x: test_x,\n",
    "                                      y_: test_y,\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "0.131313\n",
      "Round 10\n",
      "0.254545\n",
      "Round 20\n",
      "0.268687\n",
      "Round 30\n",
      "0.331313\n",
      "Round 40\n",
      "0.369697\n",
      "Round 50\n",
      "0.39798\n",
      "Round 60\n",
      "0.432323\n",
      "Round 70\n",
      "0.450505\n",
      "Round 80\n",
      "0.464646\n",
      "Round 90\n",
      "0.494949\n",
      "Round 100\n",
      "0.513131\n",
      "Round 110\n",
      "0.561616\n",
      "Round 120\n",
      "0.541414\n",
      "Round 130\n",
      "0.555556\n",
      "Round 140\n",
      "0.577778\n",
      "Round 150\n",
      "0.589899\n",
      "Round 160\n",
      "0.606061\n",
      "Round 170\n",
      "0.608081\n",
      "Round 180\n",
      "0.612121\n",
      "Round 190\n",
      "0.612121\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    train_cycle()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Round {}\".format(i))\n",
    "        test_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 200\n",
      "0.614141\n",
      "Round 210\n",
      "0.640404\n",
      "Round 220\n",
      "0.642424\n",
      "Round 230\n",
      "0.654545\n",
      "Round 240\n",
      "0.662626\n",
      "Round 250\n",
      "0.674747\n",
      "Round 260\n",
      "0.650505\n",
      "Round 270\n",
      "0.666667\n",
      "Round 280\n",
      "0.662626\n",
      "Round 290\n",
      "0.664646\n",
      "Round 300\n",
      "0.680808\n",
      "Round 310\n",
      "0.678788\n",
      "Round 320\n",
      "0.680808\n",
      "Round 330\n",
      "0.686869\n",
      "Round 340\n",
      "0.688889\n",
      "Round 350\n",
      "0.692929\n",
      "Round 360\n",
      "0.674747\n",
      "Round 370\n",
      "0.688889\n",
      "Round 380\n",
      "0.707071\n",
      "Round 390\n",
      "0.682828\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    train_cycle()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Round {}\".format(200 + i))\n",
    "        test_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 400\n",
      "0.70101\n",
      "Round 410\n",
      "0.705051\n",
      "Round 420\n",
      "0.692929\n",
      "Round 430\n",
      "0.69495\n",
      "Round 440\n",
      "0.70303\n",
      "Round 450\n",
      "0.690909\n",
      "Round 460\n",
      "0.69495\n",
      "Round 470\n",
      "0.69899\n",
      "Round 480\n",
      "0.69899\n",
      "Round 490\n",
      "0.69697\n",
      "Round 500\n",
      "0.723232\n",
      "Round 510\n",
      "0.690909\n",
      "Round 520\n",
      "0.69697\n",
      "Round 530\n",
      "0.715151\n",
      "Round 540\n",
      "0.715151\n",
      "Round 550\n",
      "0.70101\n",
      "Round 560\n",
      "0.717172\n",
      "Round 570\n",
      "0.70303\n",
      "Round 580\n",
      "0.717172\n",
      "Round 590\n",
      "0.711111\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    train_cycle()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Round {}\".format(400 + i))\n",
    "        test_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
